{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd1edb6-4bd6-414d-ba2e-7bbcc50529b1",
   "metadata": {},
   "source": [
    "### This notebook shows the usage for the first part of the ingestion pipeline - loading in data from Kaggle.\n",
    "\n",
    "Code located in Loader/KaggleDatasetLoader.py\n",
    "\n",
    "Kaggle account permisions have been included in Loader/kaggle.json. Initializing the loader will move these permissions to '~/.kaggle' if you don't have a kaggle.json there. This is needed to use the kaggle api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c9d307-01cd-4b8f-bec7-786d49c367a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json file is already in ~/.kaggle\n",
      "Permissions of /Users/williamshabecoff/.kaggle/kaggle.json are currently private\n"
     ]
    }
   ],
   "source": [
    "from Loader.KaggleDatasetLoader import KaggleDatasetLoader\n",
    "\n",
    "loader = KaggleDatasetLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f5c00-c6c0-4d5f-823c-fe1b8a218f7c",
   "metadata": {},
   "source": [
    "### Using the loader\n",
    "\n",
    "Calling loader.get_dataset() will make a new directory in 'Data/Text'. get_dataset() just needs the user and dataset name.  url = 'jeet2016/us-financial-news-articles' or url = 'https://www.kaggle.com/datasets/jeet2016/us-financial-news-articles' will work for example.\n",
    "\n",
    "Apologies that kaggle api does not support a progress bar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55e992f-0ac8-413a-b282-95ca4daed806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset into ./Data/Text/us-financial-news-articles. This may take a few minutes\n",
      "Dataset URL: https://www.kaggle.com/datasets/jeet2016/us-financial-news-articles\n"
     ]
    }
   ],
   "source": [
    "loader.get_dataset('https://www.kaggle.com/datasets/jeet2016/us-financial-news-articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d120ef4-931b-4f8e-a157-3ac69adba3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset into ./Data/Text/football-news-articles. This may take a few minutes\n",
      "Dataset URL: https://www.kaggle.com/datasets/hammadjavaid/football-news-articles\n"
     ]
    }
   ],
   "source": [
    "loader.get_dataset('hammadjavaid/football-news-articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e42f3c-c4ed-4e3d-bd06-8402f0c416ff",
   "metadata": {},
   "source": [
    "We now have a csv dataset at 'Data/Text/football-news-articles' and a json dataset at 'Data/Text/us-financial-news-articles'. We will now use the loader to reformat these datasets.  We use a config to describe a simple mapping into a standard form.  Here is football.yaml, found in Loader/schema\n",
    "\n",
    "\n",
    "```yaml\n",
    "Format: csv \n",
    "Mapping:\n",
    "  title: title\n",
    "  text: content\n",
    "  url: link\n",
    "  author: author\n",
    "```\n",
    "\n",
    "In the mapping, we have output columns of ['title', 'text', 'url', 'author'] which are found at ['title', 'content','url', 'author'].  Make sure not to change outputs columns of 'title' and 'text' because our TextDataset class expects these columns.\n",
    "\n",
    "Formats supported are ['csv', 'single_json', 'multi_json'].  Single vs multi json describes if each json file contains one document or a number of documents. If the dataset includes some metadata that we don't want in our final dataset (and this metadata uses the same extension as the rest of the data) - you will need to remove it before running reformat.  This is not necessary for our kaggle datasets.  Using delete = True will remove the data pre-transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bafa414c-293f-42b2-bfcc-0ccbfe8d1dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming files at ./Data/Text/football-news-articles into standardized format: 100%|█| 7/7 [00:02<00:00,  3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted original directory: ./Data/Text/football-news-articles\n"
     ]
    }
   ],
   "source": [
    "loader.format_dataset('football-news-articles', 'football.yaml', delete = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f20f84-d006-4086-8516-2ff0de1fac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed .zip file: ./Data/Text/us-financial-news-articles/3811_112b52537b67659ad3609a234388c50a/2018_01_112b52537b67659ad3609a234388c50a.zip\n",
      "Removed .zip file: ./Data/Text/us-financial-news-articles/3811_112b52537b67659ad3609a234388c50a/2018_04_112b52537b67659ad3609a234388c50a.zip\n",
      "Removed .zip file: ./Data/Text/us-financial-news-articles/3811_112b52537b67659ad3609a234388c50a/2018_03_112b52537b67659ad3609a234388c50a.zip\n",
      "Removed .zip file: ./Data/Text/us-financial-news-articles/3811_112b52537b67659ad3609a234388c50a/2018_05_112b52537b67659ad3609a234388c50a.zip\n",
      "Removed .zip file: ./Data/Text/us-financial-news-articles/3811_112b52537b67659ad3609a234388c50a/2018_02_112b52537b67659ad3609a234388c50a.zip\n",
      "Removed empty directory: ./Data/Text/us-financial-news-articles/3811_112b52537b67659ad3609a234388c50a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming files into standardized format: 0it [00:00, ?it/s]\n",
      "Transforming files into standardized format: 100%|██████████████████████| 57456/57456 [00:12<00:00, 4643.56it/s]\n",
      "Transforming files into standardized format: 100%|██████████████████████| 63245/63245 [00:13<00:00, 4522.07it/s]\n",
      "Transforming files into standardized format: 100%|██████████████████████| 64592/64592 [00:16<00:00, 3948.34it/s]\n",
      "Transforming files into standardized format: 100%|██████████████████████| 57802/57802 [00:13<00:00, 4266.67it/s]\n",
      "Transforming files into standardized format: 100%|██████████████████████| 63147/63147 [00:16<00:00, 3878.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted original directory: ./Data/Text/us-financial-news-articles\n"
     ]
    }
   ],
   "source": [
    "loader.format_dataset('us-financial-news-articles', 'financial.yaml', delete = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa14ad2-bab7-4209-8be1-7aeb49fd64ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfootball-articles-sample\u001b[m\u001b[m            \u001b[34mus-financial-news-articles-standard\u001b[m\u001b[m\n",
      "\u001b[34mfootball-news-articles-standard\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls Data/Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13126400-9851-4ccc-81ac-1893327f1d70",
   "metadata": {},
   "source": [
    "We now have our two standard datasets.  You may also see football-articles-sample, which comes with the repo as a smaller sample of data to demo the other ingestion functionalities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text-processing-env)",
   "language": "python",
   "name": "text-processing-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
